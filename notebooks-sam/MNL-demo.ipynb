{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNL demo\n",
    "\n",
    "Sam Maurer | Python 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/anaconda3/envs/ual-model/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from urbansim_templates import modelmanager as mm\n",
    "from urbansim_templates.models import BinaryLogitStep, OLSRegressionStep, SmallMultinomialLogitStep\n",
    "import orca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load any script-based Orca registrations\n",
    "from scripts import datasources\n",
    "from scripts import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOUSEHOLDS\n",
      "['household_id', 'taz', 'serialno', 'puma5', 'income', 'persons', 'hht', 'unittype', 'noc', 'bldgsz', 'tenure', 'vehicl', 'hinccat1', 'hinccat2', 'hhagecat', 'hsizecat', 'hfamily', 'hunittype', 'hnoccat', 'hwrkrcat', 'h0004', 'h0511', 'h1215', 'h1617', 'h1824', 'h2534', 'h3549', 'h5064', 'h6579', 'h80up', 'hworkers', 'hwork_f', 'hwork_p', 'huniv', 'hnwork', 'hretire', 'hpresch', 'hschpred', 'hschdriv', 'htypdwel', 'hownrent', 'hadnwst', 'hadwpst', 'hadkids', 'bucketbin', 'originalpuma', 'hmultiunit', 'building_id']\n",
      "\n",
      "BUILDINGS\n",
      "['building_id', 'parcel_id', 'development_type_id', 'improvement_value', 'residential_units', 'residential_sqft', 'sqft_per_unit', 'non_residential_sqft', 'building_sqft', 'nonres_rent_per_sqft', 'res_price_per_sqft', 'stories', 'year_built', 'redfin_sale_price', 'redfin_sale_year', 'redfin_home_type', 'costar_property_type', 'costar_rent', 'building_type_id']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for table_name in orca.list_tables():\n",
    "    print(table_name.upper())\n",
    "    print(orca.get_table(table_name).to_frame().columns.tolist())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small MNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca.get_table('households').to_frame(['tenure']).tenure.unique()\n",
    "\n",
    "# i think 1=own w/mortgage, 2=own free&clear, 3=rent, 4=no payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SmallMultinomialLogitStep()\n",
    "m.tables = ['households']\n",
    "m.choice_column = 'tenure'\n",
    "m.filters = ['household_id % 1000 < 1',\n",
    "             'tenure < 4']\n",
    "\n",
    "m.model_expression = OrderedDict([\n",
    "    ('intercept', [2,3]),        \n",
    "    ('income', [1,3]),\n",
    "    ('persons', [1,3])])\n",
    "\n",
    "m.name = 'small-mnl-test'\n",
    "m.tags = ['sam', 'testing']\n",
    "m.out_column = 'taz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m._get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -2,828.9266\n",
      "Initial Log-likelihood: -2,828.9266\n",
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -2,419.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/anaconda3/envs/ual-model/lib/python3.6/site-packages/scipy/optimize/_minimize.py:420: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                     _chosen   No. Observations:                2,575\n",
      "Model:             Multinomial Logit Model   Df Residuals:                    2,569\n",
      "Method:                                MLE   Df Model:                            6\n",
      "Date:                     Fri, 23 Mar 2018   Pseudo R-squ.:                   0.145\n",
      "Time:                             21:35:44   Pseudo R-bar-squ.:               0.143\n",
      "AIC:                             4,850.866   Log-Likelihood:             -2,419.433\n",
      "BIC:                             4,885.988   LL-Null:                    -2,828.927\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "intercept_2     0.0230      0.132      0.174      0.862      -0.236       0.282\n",
      "intercept_3     1.0465      0.100     10.498      0.000       0.851       1.242\n",
      "income_1     5.679e-06   9.82e-07      5.782      0.000    3.75e-06     7.6e-06\n",
      "income_3    -6.051e-06   1.17e-06     -5.156      0.000   -8.35e-06   -3.75e-06\n",
      "persons_1       0.2631      0.045      5.881      0.000       0.175       0.351\n",
      "persons_3       0.1563      0.046      3.431      0.001       0.067       0.246\n",
      "===============================================================================\n",
      "CPU times: user 1.33 s, sys: 904 ms, total: 2.23 s\n",
      "Wall time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.608019e+06\n",
       "mean     7.526463e+02\n",
       "std      4.301403e+02\n",
       "min      1.000000e+00\n",
       "25%      3.760000e+02\n",
       "50%      7.630000e+02\n",
       "75%      1.146000e+03\n",
       "max      1.454000e+03\n",
       "Name: taz, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca.get_table('households').to_frame().taz.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 3.18 s, total: 13.3 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.608019e+06\n",
       "mean     1.949268e+00\n",
       "std      9.233045e-01\n",
       "min      1.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      2.000000e+00\n",
       "75%      3.000000e+00\n",
       "max      3.000000e+00\n",
       "Name: taz, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orca.get_table('households').to_frame().taz.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to configs/small-mnl-test.pkl\n"
     ]
    }
   ],
   "source": [
    "m.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.get_step('small-mnl-test').run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -2,828.9266\n",
      "Initial Log-likelihood: -2,828.9266\n",
      "Estimation Time for Point Estimation: 0.05 seconds.\n",
      "Final log-likelihood: -2,419.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/anaconda3/envs/ual-model/lib/python3.6/site-packages/scipy/optimize/_minimize.py:420: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                     _chosen   No. Observations:                2,575\n",
      "Model:             Multinomial Logit Model   Df Residuals:                    2,569\n",
      "Method:                                MLE   Df Model:                            6\n",
      "Date:                     Fri, 23 Mar 2018   Pseudo R-squ.:                   0.145\n",
      "Time:                             21:36:15   Pseudo R-bar-squ.:               0.143\n",
      "AIC:                             4,850.866   Log-Likelihood:             -2,419.433\n",
      "BIC:                             4,885.988   LL-Null:                    -2,828.927\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "intercept_2     0.0230      0.132      0.174      0.862      -0.236       0.282\n",
      "intercept_3     1.0465      0.100     10.498      0.000       0.851       1.242\n",
      "income_1     5.679e-06   9.82e-07      5.782      0.000    3.75e-06     7.6e-06\n",
      "income_3    -6.051e-06   1.17e-06     -5.156      0.000   -8.35e-06   -3.75e-06\n",
      "persons_1       0.2631      0.045      5.881      0.000       0.175       0.351\n",
      "persons_3       0.1563      0.046      3.431      0.001       0.067       0.246\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "mm.get_step('small-mnl-test').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"break\")? (<ipython-input-16-5db00b99dd6a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-5db00b99dd6a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print \"break\"\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"break\")?\n"
     ]
    }
   ],
   "source": [
    "print \"break\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work for list of alternative id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for k, v in m.model_expression.items():\n",
    "    if isinstance(v, list):\n",
    "        l += v\n",
    "    else:\n",
    "        l += [v]\n",
    "        \n",
    "l = np.unique(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for (k,v) in m.model_expression.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v for (k,v) in m.model_expression.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work for Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m._get_data('predict')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = m._to_long(df, 'predict')\n",
    "print(len(long_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = m.model.predict(long_df)\n",
    "print(len(probs))\n",
    "print(probs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs2 = probs.reshape((len(df), 4))\n",
    "print(len(probs2))\n",
    "print(probs2[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumprobs = probs2.cumsum(axis=1)\n",
    "print(cumprobs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rands = np.random.random(len(df))\n",
    "diff = np.subtract(cumprobs.transpose(), rands).transpose()\n",
    "print(diff[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = (diff + 1.0).astype('i4')\n",
    "print(tk[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = np.argmax((diff + 1.0).astype('i4'), axis=1)\n",
    "print(len(choices))\n",
    "print(choices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_indexes = np.array([1,1,0,0,0])\n",
    "nums = np.arange(10)\n",
    "nums.take(choice_indexes + np.arange(5)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = m._get_data()\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alts = df['tenure'].sort_values().unique().tolist()\n",
    "\n",
    "#alts_df = pd.DataFrame({'_alt_id': alts}, index=alts)\n",
    "#alts_df.index = alts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df.index.sort_values().unique()\n",
    "\n",
    "obs_df = pd.DataFrame({'_obs_id': obs}, index=obs)\n",
    "\n",
    "print(len(obs_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df.index.sort_values().unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_prod, alts_prod = pd.core.reshape.util.cartesian_product([obs, alts])\n",
    "\n",
    "long_df = pd.DataFrame({'_obs_id': obs_prod, '_alts_id': alts_prod})\n",
    "print(len(long_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = long_df.merge(df, left_on='_obs_id', right_index=True)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "long_df['_chosen'] = 0\n",
    "long_df.loc[long_df._alts_id == long_df['tenure'], '_chosen'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(long_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = OrderedDict([('a', 'b')])\n",
    "d['a'] = 'b'\n",
    "d['c'] = 'd'\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[k[0] for k in list(d.items()) if k[0] is not 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
